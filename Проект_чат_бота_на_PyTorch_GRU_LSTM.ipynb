{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Проект_чат_бота_на_PyTorch_GRU_LSTM",
      "provenance": [],
      "collapsed_sections": [
        "1qjDSqi6UukX"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "8tnVLUnyeSwG",
        "outputId": "9a93e1d5-c4e2-4731-fa55-9cb2005760d4"
      },
      "source": [
        "!pip install torch==1.6.0 torchvision==0.7.0"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/53/914885a93a44b96c0dd1c36f36ff10afe341f091230aad68f7228d61db1e/torch-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8MB 17kB/s \n",
            "\u001b[?25hCollecting torchvision==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/dc/4a939cfbd38398f4765f712576df21425241020bfccc200af76d19088533/torchvision-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 27.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.7.0) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed torch-1.6.0 torchvision-0.7.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAFT1KVMam8K"
      },
      "source": [
        "# Загрузка библиотек\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7PKQ-gvam8K"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "from nltk.translate.bleu_score import sentence_bleu,corpus_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "import torch\n",
        "from torch.jit import script, trace\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import codecs\n",
        "from io import open\n",
        "import itertools\n",
        "import math\n",
        "from google.colab import files\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UczHEONVrN4g",
        "outputId": "61310364-df67-496d-c4ee-6fe5a4420c5a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrNTbkU1UukE"
      },
      "source": [
        "### устанавливаемым настройки обработки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flDUnVL2UukE"
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-dsATj5am8K"
      },
      "source": [
        "# Загрузка данных\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "k2NDBDkAbDHQ",
        "outputId": "56d91916-955d-48fb-c14e-b85d78fbc8da"
      },
      "source": [
        "file = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f2f3bb76-d8f6-45f6-90ec-c2de8e760555\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f2f3bb76-d8f6-45f6-90ec-c2de8e760555\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving formatted_movie_lines.txt to formatted_movie_lines.txt\n",
            "Saving movie_conversations.txt to movie_conversations.txt\n",
            "Saving movie_lines.txt to movie_lines.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8mTigJtUukG"
      },
      "source": [
        "### посмотрим на содержимое данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR15EL4Nam8L",
        "outputId": "040656bd-419e-4718-f631-cae992b47b2e"
      },
      "source": [
        "corpus_name = \"movie-dialogs\"\n",
        "corpus = os.path.join(\"data\", corpus_name)\n",
        "\n",
        "def printLines(file, n=10):\n",
        "    with open(file, 'rb') as datafile:\n",
        "        lines = datafile.readlines()\n",
        "    for line in lines[:n]:\n",
        "        print(line)\n",
        "\n",
        "printLines(\"movie_lines.txt\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\\n'\n",
            "b'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\\n'\n",
            "b'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\\n'\n",
            "b'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\\n'\n",
            "b\"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\\n\"\n",
            "b'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\\n'\n",
            "b\"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\\n\"\n",
            "b'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\\n'\n",
            "b'L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?\\n'\n",
            "b'L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\\n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur-rf5oSfDuX"
      },
      "source": [
        "### подготавливаем данные"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hBdOn0nUukH"
      },
      "source": [
        "Разбиваем каждую строку файла на словарь полей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeVF7qIBUukH"
      },
      "source": [
        "def loadLines(fileName, fields):\n",
        "    lines = {}\n",
        "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
        "        for line in f:\n",
        "            values = line.split(\" +++$+++ \")\n",
        "            # Extract fields\n",
        "            lineObj = {}\n",
        "            for i, field in enumerate(fields):\n",
        "                lineObj[field] = values[i]\n",
        "            lines[lineObj['lineID']] = lineObj\n",
        "    return lines"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_IcIob8UukI"
      },
      "source": [
        "группируем поля строк в диалоги"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAtV3TO4am8L"
      },
      "source": [
        "def loadConversations(fileName, lines, fields):\n",
        "    conversations = []\n",
        "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
        "        for line in f:\n",
        "            values = line.split(\" +++$+++ \")\n",
        "            # извлекаем поля\n",
        "            convObj = {}\n",
        "            for i, field in enumerate(fields):\n",
        "                convObj[field] = values[i]\n",
        "            # преобразуем строку в список (convObj[\"utteranceIDs\"] == \"['L598485', 'L598486', ...]\")\n",
        "            utterance_id_pattern = re.compile('L[0-9]+')\n",
        "            lineIds = utterance_id_pattern.findall(convObj[\"utteranceIDs\"])\n",
        "            # собираем\n",
        "            convObj[\"lines\"] = []\n",
        "            for lineId in lineIds:\n",
        "                convObj[\"lines\"].append(lines[lineId])\n",
        "            conversations.append(convObj)\n",
        "    return conversations"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQriTGEBUukI"
      },
      "source": [
        "извлекаем пары предложений из разговора"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw4US40HUukI"
      },
      "source": [
        "def extractSentencePairs(conversations):\n",
        "    qa_pairs = []\n",
        "    for conversation in conversations:\n",
        "        # преобразуем все строки разговора\n",
        "        for i in range(len(conversation[\"lines\"]) - 1): # игнорируем последнюю строку(для нее нет ответа)\n",
        "            inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
        "            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
        "            # Fфильтруем неправильные образцы (если один из списков пуст)\n",
        "            if inputLine and targetLine:\n",
        "                qa_pairs.append([inputLine, targetLine])\n",
        "    return qa_pairs"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipAzvJ1wUukJ"
      },
      "source": [
        "### собирем все в один файл"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5cgnZ0IUukJ"
      },
      "source": [
        "определяем новый файл"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBZh-jxFUukJ"
      },
      "source": [
        "datafile = (\"formatted_movie_lines.txt\")\n",
        "delimiter = '\\t'\n",
        "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6lXDhqMWps8"
      },
      "source": [
        "### инициализируем строки, список разговоров и идентификаторы поле"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59aXUx1aUukJ"
      },
      "source": [
        "lines = {}\n",
        "conversations = []\n",
        "MOVIE_LINES_FIELDS = [\"lineID\", \"characterID\", \"movieID\", \"character\", \"text\"]\n",
        "MOVIE_CONVERSATIONS_FIELDS = [\"character1ID\", \"character2ID\", \"movieID\", \"utteranceIDs\"]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpzWZ5JDUukJ"
      },
      "source": [
        "### загружаем строки и обрабатываем разговоры"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJXLD-BoUukK",
        "outputId": "d284a89e-c74e-4573-849f-532a65024d8f"
      },
      "source": [
        "print(\"\\nОбработка корпуса...\")\n",
        "lines = loadLines(\"movie_lines.txt\", MOVIE_LINES_FIELDS)\n",
        "print(\"\\nЗагрузка разговоров...\")\n",
        "conversations = loadConversations(\"movie_conversations.txt\", lines, MOVIE_CONVERSATIONS_FIELDS)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Обработка корпуса...\n",
            "\n",
            "Загрузка разговоров...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX4ojNvzUukK"
      },
      "source": [
        "сохраняем в CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTUauwlWUukK",
        "outputId": "39a5e5f9-579e-4702-f6eb-c9629493f7b1"
      },
      "source": [
        "print(\"\\nСохраняем в новом отформатированном формате...\")\n",
        "with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
        "    writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n",
        "    for pair in extractSentencePairs(conversations):\n",
        "        writer.writerow(pair)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Сохраняем в новом отформатированном формате...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t1IJQeAUukK"
      },
      "source": [
        "### посмотрим что получилось"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PNdy6wIam8c",
        "outputId": "ce2156ee-308d-4352-c7af-3ab74a39371c"
      },
      "source": [
        "print(\"\\nПримеры строк из файла:\")\n",
        "printLines(datafile)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Примеры строк из файла:\n",
            "b\"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\tWell, I thought we'd start with pronunciation, if that's okay with you.\\n\"\n",
            "b\"Well, I thought we'd start with pronunciation, if that's okay with you.\\tNot the hacking and gagging and spitting part.  Please.\\n\"\n",
            "b\"Not the hacking and gagging and spitting part.  Please.\\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\n\"\n",
            "b\"You're asking me out.  That's so cute. What's your name again?\\tForget it.\\n\"\n",
            "b\"No, no, it's my fault -- we didn't have a proper introduction ---\\tCameron.\\n\"\n",
            "b\"Cameron.\\tThe thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\n\"\n",
            "b\"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\tSeems like she could get a date easy enough...\\n\"\n",
            "b'Why?\\tUnsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\n'\n",
            "b\"Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\tThat's a shame.\\n\"\n",
            "b'Gosh, if only we could find Kat a boyfriend...\\tLet me see what I can do.\\n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PegYkXXGUukL"
      },
      "source": [
        "## токены слов по умолчанию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTrM46cfUukL"
      },
      "source": [
        "PAD_token = 0  # для заполнения коротких предложений\n",
        "SOS_token = 1  # начало предложения\n",
        "EOS_token = 2  # конец предложения"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-MHs6Kdam8d"
      },
      "source": [
        "class Voc:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.trimmed = False\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3  # подсчитать SOS, EOS, PAD\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.num_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.num_words] = word\n",
        "            self.num_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "    # Rудалить слова ниже определенного порога подсчета\n",
        "    def trim(self, min_count):\n",
        "        if self.trimmed:\n",
        "            return\n",
        "        self.trimmed = True\n",
        "\n",
        "        keep_words = []\n",
        "\n",
        "        for k, v in self.word2count.items():\n",
        "            if v >= min_count:\n",
        "                keep_words.append(k)\n",
        "\n",
        "        print('keep_words {} / {} = {:.4f}'.format(\n",
        "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
        "        ))\n",
        "\n",
        "        # повторно инициализируем словарь\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3 \n",
        "\n",
        "        for word in keep_words:\n",
        "            self.addWord(word)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgC1rYUVfeaw"
      },
      "source": [
        "# Собираем словарь и пары предложений вопрос/ответ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpgZsllJUukL"
      },
      "source": [
        "### Максимальная длина предложения для "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0hjZfRyUukM"
      },
      "source": [
        "MAX_LENGTH = 10 "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkrFN2ylUukM"
      },
      "source": [
        "### преобразуем строки Unicode в ASCII"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijKk7Lc_UukM"
      },
      "source": [
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFlxDR7nUukM"
      },
      "source": [
        "### чистим и нормализуем"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWLRLNLSUukM"
      },
      "source": [
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
        "    return s"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFocZQg-UukN"
      },
      "source": [
        "### чтение пары вопрос/ответ и возвращаем VOC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EWjI86LUukN"
      },
      "source": [
        "def readVocs(datafile, corpus_name):\n",
        "    print(\"Чтение строк...\")\n",
        "    # читаем файл и разбиваем на строки\n",
        "    lines = open(datafile, encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "    # разбиваем каждую строку на пары и нормализуем\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "    voc = Voc(corpus_name)\n",
        "    return voc, pairs"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5nq4bmHUukN"
      },
      "source": [
        "### возвращаем True, если оба предложения в паре находятся ниже порога MAX_LENGTH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_2mogEmUukO"
      },
      "source": [
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM7DStvdUukO"
      },
      "source": [
        "### фильтруем пары"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCIrI3dFUukO"
      },
      "source": [
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvD7nILwUukO"
      },
      "source": [
        "### собираем все в одно"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB-Le1bDUukO"
      },
      "source": [
        "def loadPrepareData(corpus, corpus_name, datafile, save_dir):\n",
        "    print(\"Начать подготовку данных для обучения ...\")\n",
        "    voc, pairs = readVocs(datafile, corpus_name)\n",
        "    print(\"Прочитано {!s} пар предложений\".format(len(pairs)))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Сокращено до {!s} пар предложений\".format(len(pairs)))\n",
        "    print(\"Подсчет слов...\")\n",
        "    for pair in pairs:\n",
        "        voc.addSentence(pair[0])\n",
        "        voc.addSentence(pair[1])\n",
        "    print(\"Количество слов:\", voc.num_words)\n",
        "    return voc, pairs"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2Io5VSuUukP"
      },
      "source": [
        "### загружаем и собираем данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1WRGMKAam8f",
        "outputId": "d3bbd19d-06b6-472d-91a5-d1fe26817a55"
      },
      "source": [
        "save_dir = os.path.join(\"/content/drive/My Drive/chatbot/GRU\", \"save\")\n",
        "voc, pairs = loadPrepareData(corpus, corpus_name, datafile, save_dir)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Начать подготовку данных для обучения ...\n",
            "Чтение строк...\n",
            "Прочитано 221282 пар предложений\n",
            "Сокращено до 64271 пар предложений\n",
            "Подсчет слов...\n",
            "Количество слов: 18008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrX3I8ebUukP"
      },
      "source": [
        "## что получилось"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq577FdvUukP",
        "outputId": "a612f0ff-dee5-477e-9537-54af4d6c474c"
      },
      "source": [
        "print(\"\\npairs:\")\n",
        "for pair in pairs[:10]:\n",
        "    print(pair)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "pairs:\n",
            "['there .', 'where ?']\n",
            "['you have my word . as a gentleman', 'you re sweet .']\n",
            "['hi .', 'looks like things worked out tonight huh ?']\n",
            "['you know chastity ?', 'i believe we share an art instructor']\n",
            "['have fun tonight ?', 'tons']\n",
            "['well no . . .', 'then that s all you had to say .']\n",
            "['then that s all you had to say .', 'but']\n",
            "['but', 'you always been this selfish ?']\n",
            "['do you listen to this crap ?', 'what crap ?']\n",
            "['what good stuff ?', 'the real you .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIc94um3UukP"
      },
      "source": [
        "## Удалим редко используемые слова из получившегося словаря"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYYlhwMUam8f",
        "outputId": "eeb01b2d-9a25-4406-d1dc-b28fbbc462e2"
      },
      "source": [
        "MIN_COUNT = 3\n",
        "\n",
        "def trimRareWords(voc, pairs, MIN_COUNT):\n",
        "    voc.trim(MIN_COUNT)\n",
        "    keep_pairs = []\n",
        "    for pair in pairs:\n",
        "        input_sentence = pair[0]\n",
        "        output_sentence = pair[1]\n",
        "        keep_input = True\n",
        "        keep_output = True\n",
        "        for word in input_sentence.split(' '):\n",
        "            if word not in voc.word2index:\n",
        "                keep_input = False\n",
        "                break\n",
        "        for word in output_sentence.split(' '):\n",
        "            if word not in voc.word2index:\n",
        "                keep_output = False\n",
        "                break\n",
        "\n",
        "\n",
        "        if keep_input and keep_output:\n",
        "            keep_pairs.append(pair)\n",
        "\n",
        "    print(\"Удаляем от {} пар до {}, {:.4f} от общего\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
        "    return keep_pairs\n",
        "\n",
        "\n",
        "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keep_words 7823 / 18005 = 0.4345\n",
            "Удаляем от 64271 пар до 53165, 0.8272 от общего\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ddt-n_pIhYQN"
      },
      "source": [
        "## Разделим на тестовые и обучающие данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mXOT_KShktJ"
      },
      "source": [
        "testpairs = pairs[45000:]\r\n",
        "pairs  = pairs[:45000]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htMUeOHXgBEd"
      },
      "source": [
        "## Подготавливаем данные для модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocfn1xhmam8g"
      },
      "source": [
        "def indexesFromSentence(voc, sentence):\n",
        "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
        "\n",
        "\n",
        "def zeroPadding(l, fillvalue=PAD_token):\n",
        "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
        "\n",
        "def binaryMatrix(l, value=PAD_token):\n",
        "    m = []\n",
        "    for i, seq in enumerate(l):\n",
        "        m.append([])\n",
        "        for token in seq:\n",
        "            if token == PAD_token:\n",
        "                m[i].append(0)\n",
        "            else:\n",
        "                m[i].append(1)\n",
        "    return m\n",
        "\n",
        "# возвращает заполненный тензор входной последовательности и длину\n",
        "def inputVar(l, voc):\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, lengths\n",
        "\n",
        "# возвращает заполненный тензор целевой последовательности, заполнение mask и максимальная длина цели\n",
        "def outputVar(l, voc):\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    mask = binaryMatrix(padList)\n",
        "    mask = torch.BoolTensor(mask)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, mask, max_target_len\n",
        "\n",
        "# возвращаем все элементы для batch\n",
        "def batch2TrainData(voc, pair_batch):\n",
        "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
        "    input_batch, output_batch = [], []\n",
        "    for pair in pair_batch:\n",
        "        input_batch.append(pair[0])\n",
        "        output_batch.append(pair[1])\n",
        "    inp, lengths = inputVar(input_batch, voc)\n",
        "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
        "    return inp, lengths, output, mask, max_target_len\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c04MzR1pUukR"
      },
      "source": [
        "### пример для проверки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGDNUWZmUukR",
        "outputId": "f64db83a-a9a6-4c92-a1e2-5d18ec463c14"
      },
      "source": [
        "small_batch_size = 5\n",
        "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
        "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
        "\n",
        "print(\"входной тензор:\", input_variable)\n",
        "print(\"длина:\", lengths)\n",
        "print(\"целевая переменная:\", target_variable)\n",
        "print(\"mask:\", mask)\n",
        "print(\"максимальная целевая длина:\", max_target_len)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "входной тензор: tensor([[  95, 2207, 2337,  147,   25],\n",
            "        [  68,   25,  112,   47,  359],\n",
            "        [   7,  197,  212,   25,    4],\n",
            "        [ 393,  117,   40,  242,    2],\n",
            "        [  36,   74,   53, 3258,    0],\n",
            "        [ 329,   64,  596,    6,    0],\n",
            "        [   4,    4,    4,    2,    0],\n",
            "        [   4,    4,    2,    0,    0],\n",
            "        [   4,    4,    0,    0,    0],\n",
            "        [   2,    2,    0,    0,    0]])\n",
            "длина: tensor([10, 10,  8,  7,  4])\n",
            "целевая переменная: tensor([[ 232,  147,  115,   18,   70],\n",
            "        [   4,   47,  371,   12,  311],\n",
            "        [ 112,    7,  774, 2670,   66],\n",
            "        [5937,   24,    6,    4,  424],\n",
            "        [  96,   36,    2,    2,   83],\n",
            "        [  53,    6,    0,    0,   70],\n",
            "        [3423,    2,    0,    0,  311],\n",
            "        [   4,    0,    0,    0,   66],\n",
            "        [   2,    0,    0,    0,   66],\n",
            "        [   0,    0,    0,    0,    2]])\n",
            "mask: tensor([[ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True, False, False,  True],\n",
            "        [ True,  True, False, False,  True],\n",
            "        [ True, False, False, False,  True],\n",
            "        [ True, False, False, False,  True],\n",
            "        [False, False, False, False,  True]])\n",
            "максимальная целевая длина: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usL8I7ZJUukR"
      },
      "source": [
        "# Модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPH7UXZsiJ4w"
      },
      "source": [
        "# GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NilTsxBVguT2"
      },
      "source": [
        "## Собираем Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zil8upGqam8g"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = embedding\n",
        "\n",
        "        # Инициализируем GRU:  для параметров входный размеров и скрытый слой установлено занчение HIDDEN_SIZE\n",
        "        # потому что наш размер ввода - это вложение слов с количеством функций HIDDEN_SIZE\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
        "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
        "\n",
        "    def forward(self, input_seq, input_lengths, hidden=None):\n",
        "        # преобразование индексов слов во вложения\n",
        "        embedded = self.embedding(input_seq)\n",
        "        # упаковываем дополнненный пакет последовательностей для модуля RNN\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
        "        # пропускаем через GRU\n",
        "        outputs, hidden = self.gru(packed, hidden)\n",
        "        # расспаковываем\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
        "        # суммируем двунаправленные выходы GRU\n",
        "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
        "        # возвращаем вывод и окончательное скрытое состояние\n",
        "        return outputs, hidden"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPDVg68Tg2E1"
      },
      "source": [
        "## Собираем функцию внимания"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0h9ys8aam8h"
      },
      "source": [
        "class Attn(nn.Module):\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(Attn, self).__init__()\n",
        "        self.method = method\n",
        "        if self.method not in ['dot', 'general', 'concat']:\n",
        "            raise ValueError(self.method, \"не является подходящим методов внимания.\")\n",
        "        self.hidden_size = hidden_size\n",
        "        if self.method == 'general':\n",
        "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
        "        elif self.method == 'concat':\n",
        "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
        "\n",
        "    def dot_score(self, hidden, encoder_output):\n",
        "        return torch.sum(hidden * encoder_output, dim=2)\n",
        "\n",
        "    def general_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(encoder_output)\n",
        "        return torch.sum(hidden * energy, dim=2)\n",
        "\n",
        "    def concat_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
        "        return torch.sum(self.v * energy, dim=2)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # рассчитать веса внимания на основе заданного метода\n",
        "        if self.method == 'general':\n",
        "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'concat':\n",
        "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'dot':\n",
        "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
        "\n",
        "        # транспонировать размеры\n",
        "        attn_energies = attn_energies.t()\n",
        "\n",
        "        # возвращаем нормализованные оценки вероятности softmax (с добавлением параметров)\n",
        "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2zsPEhxhHn5"
      },
      "source": [
        "## Модуль Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wciu-YEam8h"
      },
      "source": [
        "class LuongAttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
        "        super(LuongAttnDecoderRNN, self).__init__()\n",
        "\n",
        "        \n",
        "        self.attn_model = attn_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # определяем слои\n",
        "        self.embedding = embedding\n",
        "        self.embedding_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
        "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        self.attn = Attn(attn_model, hidden_size)\n",
        "\n",
        "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input_step)\n",
        "        embedded = self.embedding_dropout(embedded)\n",
        "        # через однонаправленный GRU\n",
        "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "        # рассчитать веса внимания из текущего вывода GRU\n",
        "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "        # умножить веса внимания на выход кодировщика, чтобы получить новый контекстный вектор взвешанной суммы\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
        "        # объединяем взвешенный вектор контекста и вывод GRU\n",
        "        rnn_output = rnn_output.squeeze(0)\n",
        "        context = context.squeeze(1)\n",
        "        concat_input = torch.cat((rnn_output, context), 1)\n",
        "        concat_output = torch.tanh(self.concat(concat_input))\n",
        "        # предсказать следующее слово\n",
        "        output = self.out(concat_output)\n",
        "        output = F.softmax(output, dim=1)\n",
        "        # возвращаем вывод и окончательное скрытое состояние\n",
        "        return output, hidden"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPW7csb_hYqd"
      },
      "source": [
        "## Оценка обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEkp32v8jbIj"
      },
      "source": [
        "Поскольку мы имеем дело с пакетами дополненных последовательностей, мы не можем просто учитывать все элементы тензора при вычислении потерь. Мы определяем, maskNLLLossчтобы вычислить наши потери на основе выходного тензора нашего декодера, целевого тензора и тензора двоичной маски, описывающего заполнение целевого тензора. Эта функция потерь вычисляет среднее отрицательное логарифмическое правдоподобие элементов, которые соответствуют 1 в тензоре маски."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbkYCrPyam8h"
      },
      "source": [
        "def maskNLLLoss(inp, target, mask):\n",
        "    nTotal = mask.sum()\n",
        "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
        "    loss = crossEntropy.masked_select(mask).mean()\n",
        "    loss = loss.to(device)\n",
        "    return loss, nTotal.item()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrp6rhXVhiEd"
      },
      "source": [
        "# Тренировка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDAQ4fnkam8i"
      },
      "source": [
        "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
        "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
        "\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    # установки параметров устройства\n",
        "    input_variable = input_variable.to(device)\n",
        "    target_variable = target_variable.to(device)\n",
        "    mask = mask.to(device)\n",
        "    lengths = lengths.to(device)\n",
        "\n",
        "    # инициализируем переменные\n",
        "    loss = 0\n",
        "    print_losses = []\n",
        "    n_totals = 0\n",
        "\n",
        "    # проход через кодировщик\n",
        "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
        "\n",
        "    # начальный ввод декодера\n",
        "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
        "    decoder_input = decoder_input.to(device)\n",
        "\n",
        "    # устанавливаем начальное скрытое состояние декодера\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    # пересылаем пакет последовательности через декодер по одному шагу\n",
        "    if use_teacher_forcing:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            \n",
        "            decoder_input = target_variable[t].view(1, -1)\n",
        "            # рассчитываем и считаем ошибку\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "    else:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            \n",
        "            _, topi = decoder_output.topk(1)\n",
        "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
        "            decoder_input = decoder_input.to(device)\n",
        "            # рассчитываем и считаем ошибку\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "\n",
        "    # выполняем обратное разложение\n",
        "    loss.backward()\n",
        "\n",
        "    # меняем градиент на месте\n",
        "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "\n",
        "    # оптимизируем веса модели\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return sum(print_losses) / n_totals"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYw-HzyAp-34",
        "outputId": "90e967c6-5898-4fd0-9a4b-ad5da309980a"
      },
      "source": [
        " max_target_len "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8nFzpWqUukT"
      },
      "source": [
        "### итерации обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZnFMurBam8i"
      },
      "source": [
        "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
        "\n",
        "    # загрузить пакеты для каждой итерации\n",
        "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
        "                      for _ in range(n_iteration)]\n",
        "\n",
        "    # инициализируем\n",
        "    print('Инициализация ...')\n",
        "    start_iteration = 1\n",
        "    print_loss = 0\n",
        "    losslist = []\n",
        "    if loadFilename:\n",
        "        start_iteration = checkpoint['iteration'] + 1\n",
        "\n",
        "    # Обучение\n",
        "    print(\"Обучение...\")\n",
        "    for iteration in range(start_iteration, n_iteration + 1):\n",
        "        training_batch = training_batches[iteration - 1]\n",
        "        # извлекаем поля из партии\n",
        "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
        "\n",
        "        # запускаем итерацию обучения с пакетом\n",
        "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
        "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
        "        print_loss += loss\n",
        "\n",
        "        # прогресс\n",
        "        if iteration % print_every == 0:\n",
        "            print_loss_avg = print_loss / print_every\n",
        "            print(\"Итерация: {}; Процент завершения: {:.1f}%; Средняя LOSS: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
        "            print_loss = 0\n",
        "            losslist.append(print_loss_avg)\n",
        "\n",
        "        # сохраняем контрольную точку\n",
        "        if (iteration % save_every == 0):\n",
        "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "            torch.save({\n",
        "                'iteration': iteration,\n",
        "                'en': encoder.state_dict(),\n",
        "                'de': decoder.state_dict(),\n",
        "                'en_opt': encoder_optimizer.state_dict(),\n",
        "                'de_opt': decoder_optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "                'voc_dict': voc.__dict__,\n",
        "                'embedding': embedding.state_dict()\n",
        "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))\n",
        "    return losslist\n",
        "       \n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBcd6kqoUukT"
      },
      "source": [
        "### Жадное декодирование"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MxGwgcZam8j"
      },
      "source": [
        "class GreedySearchDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(GreedySearchDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, input_seq, input_length, max_length):\n",
        "        # ввод через кодировщик\n",
        "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
        "        # подготовить последний скрытый слой кодировщика для первого скрытого входа в декодере\n",
        "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "        # инициализируем вход декодера с помощью SOS_TOKEN\n",
        "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
        "        # Инициализируем тензоры для добавления декодированных слов\n",
        "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
        "        all_scores = torch.zeros([0], device=device)\n",
        "        # итеративно декодируем токены по одному слову за раз\n",
        "        for _ in range(max_length):\n",
        "            # проход через декодер\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            # получаем наиболее вероятный токен слова и его softmax\n",
        "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
        "            # записываем токен и оценку\n",
        "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
        "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
        "            # подготавливаем текущий токен к следующему входу декодера\n",
        "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
        "        # возвращаем токены и оценки\n",
        "        return all_tokens, all_scores"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxxmVgffh_7k"
      },
      "source": [
        "# Модуль проверки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12dQ9PQzam8j"
      },
      "source": [
        "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
        "    ### преобразуем вводимое предложение\n",
        "    # слово - индекс\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
        "    # создаем тензор длин\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    # перенести размеры партии в соответствии с ожиданиями моделей\n",
        "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
        "    input_batch = input_batch.to(device)\n",
        "    lengths = lengths.to(device)\n",
        "    # расшифровать предложение\n",
        "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
        "    # индекс - слово\n",
        "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
        "    return decoded_words\n",
        "\n",
        "\n",
        "def evaluateInput(encoder, decoder, searcher, voc):\n",
        "    input_sentence = ''\n",
        "    while(1):\n",
        "        try:\n",
        "            # получить вводное предложение\n",
        "            input_sentence = input('> ')\n",
        "            # функция для выхода\n",
        "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
        "            # нормализовать предложение\n",
        "            input_sentence = normalizeString(input_sentence)\n",
        "            # оценить предложение\n",
        "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
        "            # распечатать ответ\n",
        "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "            print('Black:', ' '.join(output_words))\n",
        "\n",
        "        except KeyError:\n",
        "            print(\"Error: обнаружено неизвестное слово.\")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL3WFncsiKq4"
      },
      "source": [
        "# Обучаем модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5UpS2VpUukU"
      },
      "source": [
        "### параметры модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJe7Vt6zUukU"
      },
      "source": [
        "model_name = 'cb_model'\n",
        "attn_model = 'dot'\n",
        "#attn_model = 'general'\n",
        "#attn_model = 'concat'\n",
        "hidden_size = 512\n",
        "encoder_n_layers = 2\n",
        "decoder_n_layers = 2\n",
        "dropout = 0.5\n",
        "batch_size = 256"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpqMSZ0CUukU"
      },
      "source": [
        "### загрузка контрольной точки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDMNI33BUukU"
      },
      "source": [
        "loadFilename = None\n",
        "checkpoint_iter = 1000\n",
        "#loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
        "#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
        "#                            '{}_checkpoint.tar'.format(checkpoint_iter))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeQsEOTFUukU"
      },
      "source": [
        "### загрузить модель если есть контрольные точки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3L6z7TSUukV"
      },
      "source": [
        "if loadFilename:\n",
        "    checkpoint = torch.load(loadFilename)\n",
        "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
        "    encoder_sd = checkpoint['en']\n",
        "    decoder_sd = checkpoint['de']\n",
        "    encoder_optimizer_sd = checkpoint['en_opt']\n",
        "    decoder_optimizer_sd = checkpoint['de_opt']\n",
        "    embedding_sd = checkpoint['embedding']\n",
        "    voc.__dict__ = checkpoint['voc_dict']"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z30AWFVUukV"
      },
      "source": [
        "### собираем модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3ZoUizvam8j",
        "outputId": "a2185deb-870d-4462-c7da-b547ef5a4e2b"
      },
      "source": [
        "print('Собираем encoder and decoder ...')\n",
        "\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "if loadFilename:\n",
        "    embedding.load_state_dict(embedding_sd)\n",
        "\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "if loadFilename:\n",
        "    encoder.load_state_dict(encoder_sd)\n",
        "    decoder.load_state_dict(decoder_sd)\n",
        "\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "print('Модель собрана и готова к работе =)!')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Собираем encoder and decoder ...\n",
            "Модель собрана и готова к работе =)!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3HF1zvWUukV"
      },
      "source": [
        "### настройки обучения/оптимизации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EBr_U-jUukV"
      },
      "source": [
        "clip = 50.0\n",
        "teacher_forcing_ratio = 1.0\n",
        "learning_rate = 0.0001\n",
        "decoder_learning_ratio = 5.0\n",
        "n_iteration = 2000\n",
        "print_every = 10\n",
        "save_every = 500"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z0_SIKEam8k",
        "outputId": "eee61ffa-e468-4f14-b576-0136d6f23a3a"
      },
      "source": [
        "encoder.train()\n",
        "decoder.train()\n",
        "\n",
        "\n",
        "print('Оптимизатор построен ...')\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "if loadFilename:\n",
        "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
        "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
        "\n",
        "\n",
        "for state in encoder_optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.cuda()\n",
        "\n",
        "for state in decoder_optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.cuda()\n",
        "    "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Оптимизатор построен ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le4HtkJcUukW"
      },
      "source": [
        "### запуск обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmIc_324UukW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba03c266-d01a-45ce-8ce3-2a378c0dd3c6"
      },
      "source": [
        "print(\"Начало обучения!\")\n",
        "GRU = trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
        "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
        "           print_every, save_every, clip, corpus_name, loadFilename)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Начало обучения!\n",
            "Инициализация ...\n",
            "Обучение...\n",
            "Итерация: 10; Процент завершения: 0.5%; Средняя LOSS: 7.7554\n",
            "Итерация: 20; Процент завершения: 1.0%; Средняя LOSS: 5.4220\n",
            "Итерация: 30; Процент завершения: 1.5%; Средняя LOSS: 4.8190\n",
            "Итерация: 40; Процент завершения: 2.0%; Средняя LOSS: 4.6984\n",
            "Итерация: 50; Процент завершения: 2.5%; Средняя LOSS: 4.6137\n",
            "Итерация: 60; Процент завершения: 3.0%; Средняя LOSS: 4.5315\n",
            "Итерация: 70; Процент завершения: 3.5%; Средняя LOSS: 4.5111\n",
            "Итерация: 80; Процент завершения: 4.0%; Средняя LOSS: 4.4495\n",
            "Итерация: 90; Процент завершения: 4.5%; Средняя LOSS: 4.3920\n",
            "Итерация: 100; Процент завершения: 5.0%; Средняя LOSS: 4.3639\n",
            "Итерация: 110; Процент завершения: 5.5%; Средняя LOSS: 4.3325\n",
            "Итерация: 120; Процент завершения: 6.0%; Средняя LOSS: 4.3384\n",
            "Итерация: 130; Процент завершения: 6.5%; Средняя LOSS: 4.2728\n",
            "Итерация: 140; Процент завершения: 7.0%; Средняя LOSS: 4.2481\n",
            "Итерация: 150; Процент завершения: 7.5%; Средняя LOSS: 4.1907\n",
            "Итерация: 160; Процент завершения: 8.0%; Средняя LOSS: 4.1192\n",
            "Итерация: 170; Процент завершения: 8.5%; Средняя LOSS: 4.1279\n",
            "Итерация: 180; Процент завершения: 9.0%; Средняя LOSS: 4.0799\n",
            "Итерация: 190; Процент завершения: 9.5%; Средняя LOSS: 4.0271\n",
            "Итерация: 200; Процент завершения: 10.0%; Средняя LOSS: 4.0271\n",
            "Итерация: 210; Процент завершения: 10.5%; Средняя LOSS: 4.0133\n",
            "Итерация: 220; Процент завершения: 11.0%; Средняя LOSS: 3.9933\n",
            "Итерация: 230; Процент завершения: 11.5%; Средняя LOSS: 3.9234\n",
            "Итерация: 240; Процент завершения: 12.0%; Средняя LOSS: 3.9027\n",
            "Итерация: 250; Процент завершения: 12.5%; Средняя LOSS: 3.9513\n",
            "Итерация: 260; Процент завершения: 13.0%; Средняя LOSS: 3.9002\n",
            "Итерация: 270; Процент завершения: 13.5%; Средняя LOSS: 3.8768\n",
            "Итерация: 280; Процент завершения: 14.0%; Средняя LOSS: 3.8470\n",
            "Итерация: 290; Процент завершения: 14.5%; Средняя LOSS: 3.8510\n",
            "Итерация: 300; Процент завершения: 15.0%; Средняя LOSS: 3.8430\n",
            "Итерация: 310; Процент завершения: 15.5%; Средняя LOSS: 3.8544\n",
            "Итерация: 320; Процент завершения: 16.0%; Средняя LOSS: 3.8341\n",
            "Итерация: 330; Процент завершения: 16.5%; Средняя LOSS: 3.7994\n",
            "Итерация: 340; Процент завершения: 17.0%; Средняя LOSS: 3.7883\n",
            "Итерация: 350; Процент завершения: 17.5%; Средняя LOSS: 3.7571\n",
            "Итерация: 360; Процент завершения: 18.0%; Средняя LOSS: 3.7522\n",
            "Итерация: 370; Процент завершения: 18.5%; Средняя LOSS: 3.7732\n",
            "Итерация: 380; Процент завершения: 19.0%; Средняя LOSS: 3.7517\n",
            "Итерация: 390; Процент завершения: 19.5%; Средняя LOSS: 3.7459\n",
            "Итерация: 400; Процент завершения: 20.0%; Средняя LOSS: 3.7227\n",
            "Итерация: 410; Процент завершения: 20.5%; Средняя LOSS: 3.6921\n",
            "Итерация: 420; Процент завершения: 21.0%; Средняя LOSS: 3.7361\n",
            "Итерация: 430; Процент завершения: 21.5%; Средняя LOSS: 3.7118\n",
            "Итерация: 440; Процент завершения: 22.0%; Средняя LOSS: 3.6834\n",
            "Итерация: 450; Процент завершения: 22.5%; Средняя LOSS: 3.7239\n",
            "Итерация: 460; Процент завершения: 23.0%; Средняя LOSS: 3.6505\n",
            "Итерация: 470; Процент завершения: 23.5%; Средняя LOSS: 3.6475\n",
            "Итерация: 480; Процент завершения: 24.0%; Средняя LOSS: 3.6675\n",
            "Итерация: 490; Процент завершения: 24.5%; Средняя LOSS: 3.6640\n",
            "Итерация: 500; Процент завершения: 25.0%; Средняя LOSS: 3.6445\n",
            "Итерация: 510; Процент завершения: 25.5%; Средняя LOSS: 3.6579\n",
            "Итерация: 520; Процент завершения: 26.0%; Средняя LOSS: 3.6246\n",
            "Итерация: 530; Процент завершения: 26.5%; Средняя LOSS: 3.6196\n",
            "Итерация: 540; Процент завершения: 27.0%; Средняя LOSS: 3.5951\n",
            "Итерация: 550; Процент завершения: 27.5%; Средняя LOSS: 3.6192\n",
            "Итерация: 560; Процент завершения: 28.0%; Средняя LOSS: 3.5494\n",
            "Итерация: 570; Процент завершения: 28.5%; Средняя LOSS: 3.6150\n",
            "Итерация: 580; Процент завершения: 29.0%; Средняя LOSS: 3.5970\n",
            "Итерация: 590; Процент завершения: 29.5%; Средняя LOSS: 3.5869\n",
            "Итерация: 600; Процент завершения: 30.0%; Средняя LOSS: 3.5162\n",
            "Итерация: 610; Процент завершения: 30.5%; Средняя LOSS: 3.5180\n",
            "Итерация: 620; Процент завершения: 31.0%; Средняя LOSS: 3.5553\n",
            "Итерация: 630; Процент завершения: 31.5%; Средняя LOSS: 3.5422\n",
            "Итерация: 640; Процент завершения: 32.0%; Средняя LOSS: 3.5423\n",
            "Итерация: 650; Процент завершения: 32.5%; Средняя LOSS: 3.5692\n",
            "Итерация: 660; Процент завершения: 33.0%; Средняя LOSS: 3.5665\n",
            "Итерация: 670; Процент завершения: 33.5%; Средняя LOSS: 3.5413\n",
            "Итерация: 680; Процент завершения: 34.0%; Средняя LOSS: 3.5397\n",
            "Итерация: 690; Процент завершения: 34.5%; Средняя LOSS: 3.5027\n",
            "Итерация: 700; Процент завершения: 35.0%; Средняя LOSS: 3.5278\n",
            "Итерация: 710; Процент завершения: 35.5%; Средняя LOSS: 3.4885\n",
            "Итерация: 720; Процент завершения: 36.0%; Средняя LOSS: 3.4617\n",
            "Итерация: 730; Процент завершения: 36.5%; Средняя LOSS: 3.4537\n",
            "Итерация: 740; Процент завершения: 37.0%; Средняя LOSS: 3.4616\n",
            "Итерация: 750; Процент завершения: 37.5%; Средняя LOSS: 3.4567\n",
            "Итерация: 760; Процент завершения: 38.0%; Средняя LOSS: 3.4504\n",
            "Итерация: 770; Процент завершения: 38.5%; Средняя LOSS: 3.4665\n",
            "Итерация: 780; Процент завершения: 39.0%; Средняя LOSS: 3.4414\n",
            "Итерация: 790; Процент завершения: 39.5%; Средняя LOSS: 3.4523\n",
            "Итерация: 800; Процент завершения: 40.0%; Средняя LOSS: 3.4525\n",
            "Итерация: 810; Процент завершения: 40.5%; Средняя LOSS: 3.4172\n",
            "Итерация: 820; Процент завершения: 41.0%; Средняя LOSS: 3.4421\n",
            "Итерация: 830; Процент завершения: 41.5%; Средняя LOSS: 3.4170\n",
            "Итерация: 840; Процент завершения: 42.0%; Средняя LOSS: 3.4186\n",
            "Итерация: 850; Процент завершения: 42.5%; Средняя LOSS: 3.4228\n",
            "Итерация: 860; Процент завершения: 43.0%; Средняя LOSS: 3.3830\n",
            "Итерация: 870; Процент завершения: 43.5%; Средняя LOSS: 3.4543\n",
            "Итерация: 880; Процент завершения: 44.0%; Средняя LOSS: 3.3738\n",
            "Итерация: 890; Процент завершения: 44.5%; Средняя LOSS: 3.4173\n",
            "Итерация: 900; Процент завершения: 45.0%; Средняя LOSS: 3.3919\n",
            "Итерация: 910; Процент завершения: 45.5%; Средняя LOSS: 3.3727\n",
            "Итерация: 920; Процент завершения: 46.0%; Средняя LOSS: 3.3762\n",
            "Итерация: 930; Процент завершения: 46.5%; Средняя LOSS: 3.3310\n",
            "Итерация: 940; Процент завершения: 47.0%; Средняя LOSS: 3.3957\n",
            "Итерация: 950; Процент завершения: 47.5%; Средняя LOSS: 3.3532\n",
            "Итерация: 960; Процент завершения: 48.0%; Средняя LOSS: 3.3237\n",
            "Итерация: 970; Процент завершения: 48.5%; Средняя LOSS: 3.3451\n",
            "Итерация: 980; Процент завершения: 49.0%; Средняя LOSS: 3.3215\n",
            "Итерация: 990; Процент завершения: 49.5%; Средняя LOSS: 3.3050\n",
            "Итерация: 1000; Процент завершения: 50.0%; Средняя LOSS: 3.3433\n",
            "Итерация: 1010; Процент завершения: 50.5%; Средняя LOSS: 3.3268\n",
            "Итерация: 1020; Процент завершения: 51.0%; Средняя LOSS: 3.3184\n",
            "Итерация: 1030; Процент завершения: 51.5%; Средняя LOSS: 3.3028\n",
            "Итерация: 1040; Процент завершения: 52.0%; Средняя LOSS: 3.3214\n",
            "Итерация: 1050; Процент завершения: 52.5%; Средняя LOSS: 3.3073\n",
            "Итерация: 1060; Процент завершения: 53.0%; Средняя LOSS: 3.3478\n",
            "Итерация: 1070; Процент завершения: 53.5%; Средняя LOSS: 3.3126\n",
            "Итерация: 1080; Процент завершения: 54.0%; Средняя LOSS: 3.2850\n",
            "Итерация: 1090; Процент завершения: 54.5%; Средняя LOSS: 3.2734\n",
            "Итерация: 1100; Процент завершения: 55.0%; Средняя LOSS: 3.3062\n",
            "Итерация: 1110; Процент завершения: 55.5%; Средняя LOSS: 3.2837\n",
            "Итерация: 1120; Процент завершения: 56.0%; Средняя LOSS: 3.2812\n",
            "Итерация: 1130; Процент завершения: 56.5%; Средняя LOSS: 3.2668\n",
            "Итерация: 1140; Процент завершения: 57.0%; Средняя LOSS: 3.2580\n",
            "Итерация: 1150; Процент завершения: 57.5%; Средняя LOSS: 3.2800\n",
            "Итерация: 1160; Процент завершения: 58.0%; Средняя LOSS: 3.2083\n",
            "Итерация: 1170; Процент завершения: 58.5%; Средняя LOSS: 3.2567\n",
            "Итерация: 1180; Процент завершения: 59.0%; Средняя LOSS: 3.2278\n",
            "Итерация: 1190; Процент завершения: 59.5%; Средняя LOSS: 3.2112\n",
            "Итерация: 1200; Процент завершения: 60.0%; Средняя LOSS: 3.2276\n",
            "Итерация: 1210; Процент завершения: 60.5%; Средняя LOSS: 3.2290\n",
            "Итерация: 1220; Процент завершения: 61.0%; Средняя LOSS: 3.2227\n",
            "Итерация: 1230; Процент завершения: 61.5%; Средняя LOSS: 3.2152\n",
            "Итерация: 1240; Процент завершения: 62.0%; Средняя LOSS: 3.2353\n",
            "Итерация: 1250; Процент завершения: 62.5%; Средняя LOSS: 3.2089\n",
            "Итерация: 1260; Процент завершения: 63.0%; Средняя LOSS: 3.1944\n",
            "Итерация: 1270; Процент завершения: 63.5%; Средняя LOSS: 3.1756\n",
            "Итерация: 1280; Процент завершения: 64.0%; Средняя LOSS: 3.1997\n",
            "Итерация: 1290; Процент завершения: 64.5%; Средняя LOSS: 3.1984\n",
            "Итерация: 1300; Процент завершения: 65.0%; Средняя LOSS: 3.1910\n",
            "Итерация: 1310; Процент завершения: 65.5%; Средняя LOSS: 3.1596\n",
            "Итерация: 1320; Процент завершения: 66.0%; Средняя LOSS: 3.1840\n",
            "Итерация: 1330; Процент завершения: 66.5%; Средняя LOSS: 3.1623\n",
            "Итерация: 1340; Процент завершения: 67.0%; Средняя LOSS: 3.1654\n",
            "Итерация: 1350; Процент завершения: 67.5%; Средняя LOSS: 3.1365\n",
            "Итерация: 1360; Процент завершения: 68.0%; Средняя LOSS: 3.2062\n",
            "Итерация: 1370; Процент завершения: 68.5%; Средняя LOSS: 3.1364\n",
            "Итерация: 1380; Процент завершения: 69.0%; Средняя LOSS: 3.1487\n",
            "Итерация: 1390; Процент завершения: 69.5%; Средняя LOSS: 3.1247\n",
            "Итерация: 1400; Процент завершения: 70.0%; Средняя LOSS: 3.1062\n",
            "Итерация: 1410; Процент завершения: 70.5%; Средняя LOSS: 3.1455\n",
            "Итерация: 1420; Процент завершения: 71.0%; Средняя LOSS: 3.1482\n",
            "Итерация: 1430; Процент завершения: 71.5%; Средняя LOSS: 3.1130\n",
            "Итерация: 1440; Процент завершения: 72.0%; Средняя LOSS: 3.1299\n",
            "Итерация: 1450; Процент завершения: 72.5%; Средняя LOSS: 3.1286\n",
            "Итерация: 1460; Процент завершения: 73.0%; Средняя LOSS: 3.0929\n",
            "Итерация: 1470; Процент завершения: 73.5%; Средняя LOSS: 3.0560\n",
            "Итерация: 1480; Процент завершения: 74.0%; Средняя LOSS: 3.0945\n",
            "Итерация: 1490; Процент завершения: 74.5%; Средняя LOSS: 3.0966\n",
            "Итерация: 1500; Процент завершения: 75.0%; Средняя LOSS: 3.0973\n",
            "Итерация: 1510; Процент завершения: 75.5%; Средняя LOSS: 3.1128\n",
            "Итерация: 1520; Процент завершения: 76.0%; Средняя LOSS: 3.0872\n",
            "Итерация: 1530; Процент завершения: 76.5%; Средняя LOSS: 3.0572\n",
            "Итерация: 1540; Процент завершения: 77.0%; Средняя LOSS: 3.0941\n",
            "Итерация: 1550; Процент завершения: 77.5%; Средняя LOSS: 3.0665\n",
            "Итерация: 1560; Процент завершения: 78.0%; Средняя LOSS: 3.0692\n",
            "Итерация: 1570; Процент завершения: 78.5%; Средняя LOSS: 3.0312\n",
            "Итерация: 1580; Процент завершения: 79.0%; Средняя LOSS: 3.0924\n",
            "Итерация: 1590; Процент завершения: 79.5%; Средняя LOSS: 3.0715\n",
            "Итерация: 1600; Процент завершения: 80.0%; Средняя LOSS: 3.0697\n",
            "Итерация: 1610; Процент завершения: 80.5%; Средняя LOSS: 3.0522\n",
            "Итерация: 1620; Процент завершения: 81.0%; Средняя LOSS: 2.9955\n",
            "Итерация: 1630; Процент завершения: 81.5%; Средняя LOSS: 3.0195\n",
            "Итерация: 1640; Процент завершения: 82.0%; Средняя LOSS: 3.0647\n",
            "Итерация: 1650; Процент завершения: 82.5%; Средняя LOSS: 3.0264\n",
            "Итерация: 1660; Процент завершения: 83.0%; Средняя LOSS: 3.0195\n",
            "Итерация: 1670; Процент завершения: 83.5%; Средняя LOSS: 3.0316\n",
            "Итерация: 1680; Процент завершения: 84.0%; Средняя LOSS: 3.0322\n",
            "Итерация: 1690; Процент завершения: 84.5%; Средняя LOSS: 3.0190\n",
            "Итерация: 1700; Процент завершения: 85.0%; Средняя LOSS: 3.0209\n",
            "Итерация: 1710; Процент завершения: 85.5%; Средняя LOSS: 3.0508\n",
            "Итерация: 1720; Процент завершения: 86.0%; Средняя LOSS: 2.9780\n",
            "Итерация: 1730; Процент завершения: 86.5%; Средняя LOSS: 3.0212\n",
            "Итерация: 1740; Процент завершения: 87.0%; Средняя LOSS: 2.9948\n",
            "Итерация: 1750; Процент завершения: 87.5%; Средняя LOSS: 2.9660\n",
            "Итерация: 1760; Процент завершения: 88.0%; Средняя LOSS: 2.9759\n",
            "Итерация: 1770; Процент завершения: 88.5%; Средняя LOSS: 2.9867\n",
            "Итерация: 1780; Процент завершения: 89.0%; Средняя LOSS: 2.9674\n",
            "Итерация: 1790; Процент завершения: 89.5%; Средняя LOSS: 2.9325\n",
            "Итерация: 1800; Процент завершения: 90.0%; Средняя LOSS: 2.9392\n",
            "Итерация: 1810; Процент завершения: 90.5%; Средняя LOSS: 2.9332\n",
            "Итерация: 1820; Процент завершения: 91.0%; Средняя LOSS: 2.9772\n",
            "Итерация: 1830; Процент завершения: 91.5%; Средняя LOSS: 2.9261\n",
            "Итерация: 1840; Процент завершения: 92.0%; Средняя LOSS: 2.9435\n",
            "Итерация: 1850; Процент завершения: 92.5%; Средняя LOSS: 2.9778\n",
            "Итерация: 1860; Процент завершения: 93.0%; Средняя LOSS: 2.9494\n",
            "Итерация: 1870; Процент завершения: 93.5%; Средняя LOSS: 2.9558\n",
            "Итерация: 1880; Процент завершения: 94.0%; Средняя LOSS: 2.9057\n",
            "Итерация: 1890; Процент завершения: 94.5%; Средняя LOSS: 2.9289\n",
            "Итерация: 1900; Процент завершения: 95.0%; Средняя LOSS: 2.9599\n",
            "Итерация: 1910; Процент завершения: 95.5%; Средняя LOSS: 2.8931\n",
            "Итерация: 1920; Процент завершения: 96.0%; Средняя LOSS: 2.8915\n",
            "Итерация: 1930; Процент завершения: 96.5%; Средняя LOSS: 2.8888\n",
            "Итерация: 1940; Процент завершения: 97.0%; Средняя LOSS: 2.8812\n",
            "Итерация: 1950; Процент завершения: 97.5%; Средняя LOSS: 2.8770\n",
            "Итерация: 1960; Процент завершения: 98.0%; Средняя LOSS: 2.8655\n",
            "Итерация: 1970; Процент завершения: 98.5%; Средняя LOSS: 2.9030\n",
            "Итерация: 1980; Процент завершения: 99.0%; Средняя LOSS: 2.8671\n",
            "Итерация: 1990; Процент завершения: 99.5%; Средняя LOSS: 2.8752\n",
            "Итерация: 2000; Процент завершения: 100.0%; Средняя LOSS: 2.8757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxBsMNGKsBLr"
      },
      "source": [
        "# визуализируем результат GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "NtaPml3as3QR",
        "outputId": "10b991d7-18ab-4d3c-92cc-699731fc94ac"
      },
      "source": [
        "plt.plot(GRU)\r\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaEyytejtyZT"
      },
      "source": [
        "## Рассчитаем Bleu score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEpvYfs8t2F5",
        "outputId": "2c343804-2bb1-40b3-f85e-017e7295312c"
      },
      "source": [
        "encoder.eval()\r\n",
        "decoder.eval()\r\n",
        "\r\n",
        "searcher = GreedySearchDecoder(encoder, decoder)\r\n",
        "gram1_bleu_score = []\r\n",
        "gram2_bleu_score = []\r\n",
        "for i in range(0,len(testpairs),1):\r\n",
        "  \r\n",
        "  input_sentence = testpairs[i][0]\r\n",
        "  \r\n",
        "  reference = testpairs[i][1:]\r\n",
        "  templist = []\r\n",
        "  for k in range(len(reference)):\r\n",
        "    if(reference[k]!=''):\r\n",
        "      temp = reference[k].split(' ')\r\n",
        "      templist.append(temp)\r\n",
        "  \r\n",
        "  \r\n",
        "  input_sentence = normalizeString(input_sentence)\r\n",
        "  output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\r\n",
        "  output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\r\n",
        "  chencherry = SmoothingFunction()\r\n",
        "  score1 = sentence_bleu(templist,output_words,weights=(1, 0, 0, 0) ,smoothing_function=chencherry.method1)\r\n",
        "  score2 = sentence_bleu(templist,output_words,weights=(0.5, 0.5, 0, 0),smoothing_function=chencherry.method1) \r\n",
        "  gram1_bleu_score.append(score1)\r\n",
        "  gram2_bleu_score.append(score2)\r\n",
        "  if i%1000 == 0:\r\n",
        "    print(i,sum(gram1_bleu_score)/len(gram1_bleu_score),sum(gram2_bleu_score)/len(gram2_bleu_score))\r\n",
        "print(\"Общая оценка Bleu Score для 1 грамм тестовых пар: \", sum(gram1_bleu_score)/len(gram1_bleu_score) )  \r\n",
        "print(\"Общая оценка Bleu Score для 2 грамм тестовых пар: \", sum(gram2_bleu_score)/len(gram2_bleu_score) )  "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.14285714285714285 0.048795003647426664\n",
            "1000 0.14983188364092512 0.06388490997068101\n",
            "2000 0.14901741338574556 0.06715010967131829\n",
            "3000 0.14510270911676368 0.06350666355931216\n",
            "4000 0.14811456374845594 0.06446823916756403\n",
            "5000 0.14879283896261034 0.06484691237332502\n",
            "6000 0.14724774320495854 0.06347329342188057\n",
            "7000 0.1484517378287078 0.06387569049187825\n",
            "8000 0.14882504662156193 0.06425083017621877\n",
            "Общая оценка Bleu Score для 1 грамм тестовых пар:  0.14784138843436995\n",
            "Общая оценка Bleu Score для 2 грамм тестовых пар:  0.06371336407501298\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qjDSqi6UukX"
      },
      "source": [
        "# Чат на GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PLpj9UIUukX",
        "outputId": "6421e8b8-1156-4774-f526-bedb6fcf3942"
      },
      "source": [
        "evaluateInput(encoder, decoder, searcher, voc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> hi\n",
            "Black: hi . . . . !\n",
            "> what are you doing?\n",
            "Black: i m looking for a phone . . .\n",
            "> okey\n",
            "Error: обнаружено неизвестное слово.\n",
            "> ok\n",
            "Black: you re not gonna get away with me .\n",
            "> q\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIzo8yTR0Awt"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB_vgrzR3vmd",
        "outputId": "442209cf-7c00-44d1-9e2b-c877f583c38e"
      },
      "source": [
        "save_dir = os.path.join(\"/content/drive/My Drive/chatbot/LSTM\", \"save\")\r\n",
        "voc, pairs = loadPrepareData(corpus, corpus_name, datafile, save_dir)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Начать подготовку данных для обучения ...\n",
            "Чтение строк...\n",
            "Прочитано 221282 пар предложений\n",
            "Сокращено до 64271 пар предложений\n",
            "Подсчет слов...\n",
            "Количество слов: 18008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsfZI-r-0Aw5"
      },
      "source": [
        "## Собираем Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_DC8JRc0Aw6"
      },
      "source": [
        "class EncoderLSTM(nn.Module):\n",
        "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
        "        super(EncoderLSTM, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = embedding\n",
        "        self.gru = nn.LSTM(hidden_size, hidden_size, n_layers,\n",
        "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
        "\n",
        "    def forward(self, input_seq, input_lengths, hidden=None):\n",
        "        \n",
        "        embedded = self.embedding(input_seq)\n",
        "        \n",
        "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
        "        \n",
        "        outputs, hidden = self.gru(packed, hidden)\n",
        "        \n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
        "        \n",
        "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
        "        \n",
        "        return outputs, hidden\n",
        "    def init_hidden(self):\n",
        "        \n",
        "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
        "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-Up-Nxg0Aw8"
      },
      "source": [
        "## Модуль Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwjtXgwA0Aw8"
      },
      "source": [
        "class LuongAttnDecoderLSTM(nn.Module):\n",
        "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
        "        super(LuongAttnDecoderLSTM, self).__init__()\n",
        "\n",
        "        \n",
        "        self.attn_model = attn_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "       \n",
        "        self.embedding = embedding\n",
        "        self.embedding_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.LSTM(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))#, bidirectional=True)\n",
        "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.attn = Attn(attn_model, hidden_size)\n",
        "    \n",
        "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input_step)\n",
        "        embedded = self.embedding_dropout(embedded)\n",
        "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
        "        rnn_output = rnn_output.squeeze(0)\n",
        "        context = context.squeeze(1)\n",
        "        concat_input = torch.cat((rnn_output, context), 1)\n",
        "        concat_output = torch.tanh(self.concat(concat_input))\n",
        "        output = self.out(concat_output)\n",
        "        output = F.softmax(output, dim=1)\n",
        "        return output, hidden"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abOCbodl2esm"
      },
      "source": [
        "# Обучаем модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acYorcG72etB"
      },
      "source": [
        "### параметры модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC-CIN0U2etC"
      },
      "source": [
        "model_name = 'cb_model'\n",
        "attn_model = 'dot'\n",
        "#attn_model = 'general'\n",
        "#attn_model = 'concat'\n",
        "hidden_size = 512\n",
        "encoder_n_layers = 2\n",
        "decoder_n_layers = 4\n",
        "dropout = 0.5\n",
        "batch_size = 256"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caKMaYgy2etD"
      },
      "source": [
        "### загрузка контрольной точки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM9htNU12etD"
      },
      "source": [
        "loadFilename = None\n",
        "checkpoint_iter = 1000\n",
        "#loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
        "#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
        "#                            '{}_checkpoint.tar'.format(checkpoint_iter))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNWKitCr2etE"
      },
      "source": [
        "### загрузить модель если есть контрольные точки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lcPVguh2etE"
      },
      "source": [
        "if loadFilename:\n",
        "    checkpoint = torch.load(loadFilename)\n",
        "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
        "    encoder_sd = checkpoint['en']\n",
        "    decoder_sd = checkpoint['de']\n",
        "    encoder_optimizer_sd = checkpoint['en_opt']\n",
        "    decoder_optimizer_sd = checkpoint['de_opt']\n",
        "    embedding_sd = checkpoint['embedding']\n",
        "    voc.__dict__ = checkpoint['voc_dict']"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzqBnhJ_2etF"
      },
      "source": [
        "### собираем модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG_0NVMM2etF",
        "outputId": "b866cd5c-95d0-48dd-d7af-4e8ba4f9527a"
      },
      "source": [
        "print('Собираем encoder and decoder ...')\n",
        "\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "if loadFilename:\n",
        "    embedding.load_state_dict(embedding_sd)\n",
        "\n",
        "encoder = EncoderLSTM(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderLSTM(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "if loadFilename:\n",
        "    encoder.load_state_dict(encoder_sd)\n",
        "    decoder.load_state_dict(decoder_sd)\n",
        "\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "print('Модель собрана и готова к работе =)!')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Собираем encoder and decoder ...\n",
            "Модель собрана и готова к работе =)!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_FImJ8h2etG"
      },
      "source": [
        "### настройки обучения/оптимизации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONRnpkDw2etH"
      },
      "source": [
        "clip = 50.0\n",
        "teacher_forcing_ratio = 1.0\n",
        "learning_rate = 0.0001\n",
        "decoder_learning_ratio = 5.0\n",
        "n_iteration = 2000\n",
        "print_every = 10\n",
        "save_every = 500"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpNdxArb2etH",
        "outputId": "730fa783-df15-4260-ea95-b006491e8869"
      },
      "source": [
        "encoder.train()\n",
        "decoder.train()\n",
        "\n",
        "\n",
        "print('Оптимизатор построен ...')\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "if loadFilename:\n",
        "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
        "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
        "\n",
        "\n",
        "for state in encoder_optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.cuda()\n",
        "\n",
        "for state in decoder_optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.cuda()\n",
        "    "
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Оптимизатор построен ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbxoRcXB2etI"
      },
      "source": [
        "### запуск обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfePqC7d2etI",
        "outputId": "161e30f6-35ff-4abd-e824-a9fa6d11bf4c"
      },
      "source": [
        "print(\"Начало обучения!\")\n",
        "LSTM = trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
        "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
        "           print_every, save_every, clip, corpus_name, loadFilename)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Начало обучения!\n",
            "Инициализация ...\n",
            "Обучение...\n",
            "Итерация: 10; Процент завершения: 0.5%; Средняя LOSS: 9.0096\n",
            "Итерация: 20; Процент завершения: 1.0%; Средняя LOSS: 6.2002\n",
            "Итерация: 30; Процент завершения: 1.5%; Средняя LOSS: 5.3237\n",
            "Итерация: 40; Процент завершения: 2.0%; Средняя LOSS: 5.2545\n",
            "Итерация: 50; Процент завершения: 2.5%; Средняя LOSS: 5.1821\n",
            "Итерация: 60; Процент завершения: 3.0%; Средняя LOSS: 5.1152\n",
            "Итерация: 70; Процент завершения: 3.5%; Средняя LOSS: 5.0106\n",
            "Итерация: 80; Процент завершения: 4.0%; Средняя LOSS: 5.0119\n",
            "Итерация: 90; Процент завершения: 4.5%; Средняя LOSS: 4.9660\n",
            "Итерация: 100; Процент завершения: 5.0%; Средняя LOSS: 4.9466\n",
            "Итерация: 110; Процент завершения: 5.5%; Средняя LOSS: 4.9167\n",
            "Итерация: 120; Процент завершения: 6.0%; Средняя LOSS: 4.9170\n",
            "Итерация: 130; Процент завершения: 6.5%; Средняя LOSS: 4.8721\n",
            "Итерация: 140; Процент завершения: 7.0%; Средняя LOSS: 4.9161\n",
            "Итерация: 150; Процент завершения: 7.5%; Средняя LOSS: 4.8752\n",
            "Итерация: 160; Процент завершения: 8.0%; Средняя LOSS: 4.8681\n",
            "Итерация: 170; Процент завершения: 8.5%; Средняя LOSS: 4.8647\n",
            "Итерация: 180; Процент завершения: 9.0%; Средняя LOSS: 4.8887\n",
            "Итерация: 190; Процент завершения: 9.5%; Средняя LOSS: 4.8630\n",
            "Итерация: 200; Процент завершения: 10.0%; Средняя LOSS: 4.8950\n",
            "Итерация: 210; Процент завершения: 10.5%; Средняя LOSS: 4.8113\n",
            "Итерация: 220; Процент завершения: 11.0%; Средняя LOSS: 4.8299\n",
            "Итерация: 230; Процент завершения: 11.5%; Средняя LOSS: 4.8711\n",
            "Итерация: 240; Процент завершения: 12.0%; Средняя LOSS: 4.8639\n",
            "Итерация: 250; Процент завершения: 12.5%; Средняя LOSS: 4.8412\n",
            "Итерация: 260; Процент завершения: 13.0%; Средняя LOSS: 4.8251\n",
            "Итерация: 270; Процент завершения: 13.5%; Средняя LOSS: 4.7581\n",
            "Итерация: 280; Процент завершения: 14.0%; Средняя LOSS: 4.6506\n",
            "Итерация: 290; Процент завершения: 14.5%; Средняя LOSS: 4.6281\n",
            "Итерация: 300; Процент завершения: 15.0%; Средняя LOSS: 4.5729\n",
            "Итерация: 310; Процент завершения: 15.5%; Средняя LOSS: 4.5921\n",
            "Итерация: 320; Процент завершения: 16.0%; Средняя LOSS: 4.5625\n",
            "Итерация: 330; Процент завершения: 16.5%; Средняя LOSS: 4.5872\n",
            "Итерация: 340; Процент завершения: 17.0%; Средняя LOSS: 4.5857\n",
            "Итерация: 350; Процент завершения: 17.5%; Средняя LOSS: 4.5554\n",
            "Итерация: 360; Процент завершения: 18.0%; Средняя LOSS: 4.5453\n",
            "Итерация: 370; Процент завершения: 18.5%; Средняя LOSS: 4.5173\n",
            "Итерация: 380; Процент завершения: 19.0%; Средняя LOSS: 4.5059\n",
            "Итерация: 390; Процент завершения: 19.5%; Средняя LOSS: 4.5204\n",
            "Итерация: 400; Процент завершения: 20.0%; Средняя LOSS: 4.4810\n",
            "Итерация: 410; Процент завершения: 20.5%; Средняя LOSS: 4.4747\n",
            "Итерация: 420; Процент завершения: 21.0%; Средняя LOSS: 4.4310\n",
            "Итерация: 430; Процент завершения: 21.5%; Средняя LOSS: 4.4297\n",
            "Итерация: 440; Процент завершения: 22.0%; Средняя LOSS: 4.4421\n",
            "Итерация: 450; Процент завершения: 22.5%; Средняя LOSS: 4.4107\n",
            "Итерация: 460; Процент завершения: 23.0%; Средняя LOSS: 4.3681\n",
            "Итерация: 470; Процент завершения: 23.5%; Средняя LOSS: 4.3920\n",
            "Итерация: 480; Процент завершения: 24.0%; Средняя LOSS: 4.4014\n",
            "Итерация: 490; Процент завершения: 24.5%; Средняя LOSS: 4.4009\n",
            "Итерация: 500; Процент завершения: 25.0%; Средняя LOSS: 4.3421\n",
            "Итерация: 510; Процент завершения: 25.5%; Средняя LOSS: 4.3885\n",
            "Итерация: 520; Процент завершения: 26.0%; Средняя LOSS: 4.3517\n",
            "Итерация: 530; Процент завершения: 26.5%; Средняя LOSS: 4.2873\n",
            "Итерация: 540; Процент завершения: 27.0%; Средняя LOSS: 4.3482\n",
            "Итерация: 550; Процент завершения: 27.5%; Средняя LOSS: 4.3298\n",
            "Итерация: 560; Процент завершения: 28.0%; Средняя LOSS: 4.3004\n",
            "Итерация: 570; Процент завершения: 28.5%; Средняя LOSS: 4.2694\n",
            "Итерация: 580; Процент завершения: 29.0%; Средняя LOSS: 4.2677\n",
            "Итерация: 590; Процент завершения: 29.5%; Средняя LOSS: 4.2542\n",
            "Итерация: 600; Процент завершения: 30.0%; Средняя LOSS: 4.2396\n",
            "Итерация: 610; Процент завершения: 30.5%; Средняя LOSS: 4.2424\n",
            "Итерация: 620; Процент завершения: 31.0%; Средняя LOSS: 4.2732\n",
            "Итерация: 630; Процент завершения: 31.5%; Средняя LOSS: 4.2483\n",
            "Итерация: 640; Процент завершения: 32.0%; Средняя LOSS: 4.2647\n",
            "Итерация: 650; Процент завершения: 32.5%; Средняя LOSS: 4.2325\n",
            "Итерация: 660; Процент завершения: 33.0%; Средняя LOSS: 4.2205\n",
            "Итерация: 670; Процент завершения: 33.5%; Средняя LOSS: 4.2126\n",
            "Итерация: 680; Процент завершения: 34.0%; Средняя LOSS: 4.2518\n",
            "Итерация: 690; Процент завершения: 34.5%; Средняя LOSS: 4.2348\n",
            "Итерация: 700; Процент завершения: 35.0%; Средняя LOSS: 4.1550\n",
            "Итерация: 710; Процент завершения: 35.5%; Средняя LOSS: 4.1792\n",
            "Итерация: 720; Процент завершения: 36.0%; Средняя LOSS: 4.2099\n",
            "Итерация: 730; Процент завершения: 36.5%; Средняя LOSS: 4.1918\n",
            "Итерация: 740; Процент завершения: 37.0%; Средняя LOSS: 4.1851\n",
            "Итерация: 750; Процент завершения: 37.5%; Средняя LOSS: 4.1484\n",
            "Итерация: 760; Процент завершения: 38.0%; Средняя LOSS: 4.1507\n",
            "Итерация: 770; Процент завершения: 38.5%; Средняя LOSS: 4.1743\n",
            "Итерация: 780; Процент завершения: 39.0%; Средняя LOSS: 4.1782\n",
            "Итерация: 790; Процент завершения: 39.5%; Средняя LOSS: 4.1843\n",
            "Итерация: 800; Процент завершения: 40.0%; Средняя LOSS: 4.1258\n",
            "Итерация: 810; Процент завершения: 40.5%; Средняя LOSS: 4.1251\n",
            "Итерация: 820; Процент завершения: 41.0%; Средняя LOSS: 4.1572\n",
            "Итерация: 830; Процент завершения: 41.5%; Средняя LOSS: 4.0979\n",
            "Итерация: 840; Процент завершения: 42.0%; Средняя LOSS: 4.1256\n",
            "Итерация: 850; Процент завершения: 42.5%; Средняя LOSS: 4.0747\n",
            "Итерация: 860; Процент завершения: 43.0%; Средняя LOSS: 4.1085\n",
            "Итерация: 870; Процент завершения: 43.5%; Средняя LOSS: 4.0977\n",
            "Итерация: 880; Процент завершения: 44.0%; Средняя LOSS: 4.1038\n",
            "Итерация: 890; Процент завершения: 44.5%; Средняя LOSS: 4.1121\n",
            "Итерация: 900; Процент завершения: 45.0%; Средняя LOSS: 4.0328\n",
            "Итерация: 910; Процент завершения: 45.5%; Средняя LOSS: 4.0903\n",
            "Итерация: 920; Процент завершения: 46.0%; Средняя LOSS: 4.0987\n",
            "Итерация: 930; Процент завершения: 46.5%; Средняя LOSS: 4.0254\n",
            "Итерация: 940; Процент завершения: 47.0%; Средняя LOSS: 4.0486\n",
            "Итерация: 950; Процент завершения: 47.5%; Средняя LOSS: 4.0567\n",
            "Итерация: 960; Процент завершения: 48.0%; Средняя LOSS: 4.0381\n",
            "Итерация: 970; Процент завершения: 48.5%; Средняя LOSS: 4.0729\n",
            "Итерация: 980; Процент завершения: 49.0%; Средняя LOSS: 4.0622\n",
            "Итерация: 990; Процент завершения: 49.5%; Средняя LOSS: 4.0237\n",
            "Итерация: 1000; Процент завершения: 50.0%; Средняя LOSS: 4.0257\n",
            "Итерация: 1010; Процент завершения: 50.5%; Средняя LOSS: 4.0146\n",
            "Итерация: 1020; Процент завершения: 51.0%; Средняя LOSS: 4.0106\n",
            "Итерация: 1030; Процент завершения: 51.5%; Средняя LOSS: 4.0201\n",
            "Итерация: 1040; Процент завершения: 52.0%; Средняя LOSS: 4.0210\n",
            "Итерация: 1050; Процент завершения: 52.5%; Средняя LOSS: 3.9553\n",
            "Итерация: 1060; Процент завершения: 53.0%; Средняя LOSS: 4.0209\n",
            "Итерация: 1070; Процент завершения: 53.5%; Средняя LOSS: 3.9944\n",
            "Итерация: 1080; Процент завершения: 54.0%; Средняя LOSS: 4.0008\n",
            "Итерация: 1090; Процент завершения: 54.5%; Средняя LOSS: 3.9976\n",
            "Итерация: 1100; Процент завершения: 55.0%; Средняя LOSS: 3.9797\n",
            "Итерация: 1110; Процент завершения: 55.5%; Средняя LOSS: 3.9799\n",
            "Итерация: 1120; Процент завершения: 56.0%; Средняя LOSS: 3.9877\n",
            "Итерация: 1130; Процент завершения: 56.5%; Средняя LOSS: 3.9991\n",
            "Итерация: 1140; Процент завершения: 57.0%; Средняя LOSS: 3.9720\n",
            "Итерация: 1150; Процент завершения: 57.5%; Средняя LOSS: 3.9200\n",
            "Итерация: 1160; Процент завершения: 58.0%; Средняя LOSS: 3.9120\n",
            "Итерация: 1170; Процент завершения: 58.5%; Средняя LOSS: 3.9279\n",
            "Итерация: 1180; Процент завершения: 59.0%; Средняя LOSS: 3.9023\n",
            "Итерация: 1190; Процент завершения: 59.5%; Средняя LOSS: 3.9246\n",
            "Итерация: 1200; Процент завершения: 60.0%; Средняя LOSS: 3.9096\n",
            "Итерация: 1210; Процент завершения: 60.5%; Средняя LOSS: 3.9418\n",
            "Итерация: 1220; Процент завершения: 61.0%; Средняя LOSS: 3.8953\n",
            "Итерация: 1230; Процент завершения: 61.5%; Средняя LOSS: 3.8653\n",
            "Итерация: 1240; Процент завершения: 62.0%; Средняя LOSS: 3.9248\n",
            "Итерация: 1250; Процент завершения: 62.5%; Средняя LOSS: 3.9134\n",
            "Итерация: 1260; Процент завершения: 63.0%; Средняя LOSS: 3.8645\n",
            "Итерация: 1270; Процент завершения: 63.5%; Средняя LOSS: 3.9139\n",
            "Итерация: 1280; Процент завершения: 64.0%; Средняя LOSS: 3.8545\n",
            "Итерация: 1290; Процент завершения: 64.5%; Средняя LOSS: 3.8537\n",
            "Итерация: 1300; Процент завершения: 65.0%; Средняя LOSS: 3.8299\n",
            "Итерация: 1310; Процент завершения: 65.5%; Средняя LOSS: 3.8273\n",
            "Итерация: 1320; Процент завершения: 66.0%; Средняя LOSS: 3.8808\n",
            "Итерация: 1330; Процент завершения: 66.5%; Средняя LOSS: 3.8632\n",
            "Итерация: 1340; Процент завершения: 67.0%; Средняя LOSS: 3.8651\n",
            "Итерация: 1350; Процент завершения: 67.5%; Средняя LOSS: 3.8397\n",
            "Итерация: 1360; Процент завершения: 68.0%; Средняя LOSS: 3.8422\n",
            "Итерация: 1370; Процент завершения: 68.5%; Средняя LOSS: 3.8544\n",
            "Итерация: 1380; Процент завершения: 69.0%; Средняя LOSS: 3.8600\n",
            "Итерация: 1390; Процент завершения: 69.5%; Средняя LOSS: 3.7936\n",
            "Итерация: 1400; Процент завершения: 70.0%; Средняя LOSS: 3.8028\n",
            "Итерация: 1410; Процент завершения: 70.5%; Средняя LOSS: 3.8350\n",
            "Итерация: 1420; Процент завершения: 71.0%; Средняя LOSS: 3.7836\n",
            "Итерация: 1430; Процент завершения: 71.5%; Средняя LOSS: 3.8075\n",
            "Итерация: 1440; Процент завершения: 72.0%; Средняя LOSS: 3.8079\n",
            "Итерация: 1450; Процент завершения: 72.5%; Средняя LOSS: 3.8170\n",
            "Итерация: 1460; Процент завершения: 73.0%; Средняя LOSS: 3.7594\n",
            "Итерация: 1470; Процент завершения: 73.5%; Средняя LOSS: 3.7968\n",
            "Итерация: 1480; Процент завершения: 74.0%; Средняя LOSS: 3.7906\n",
            "Итерация: 1490; Процент завершения: 74.5%; Средняя LOSS: 3.8070\n",
            "Итерация: 1500; Процент завершения: 75.0%; Средняя LOSS: 3.7849\n",
            "Итерация: 1510; Процент завершения: 75.5%; Средняя LOSS: 3.7791\n",
            "Итерация: 1520; Процент завершения: 76.0%; Средняя LOSS: 3.7874\n",
            "Итерация: 1530; Процент завершения: 76.5%; Средняя LOSS: 3.7990\n",
            "Итерация: 1540; Процент завершения: 77.0%; Средняя LOSS: 3.7150\n",
            "Итерация: 1550; Процент завершения: 77.5%; Средняя LOSS: 3.7446\n",
            "Итерация: 1560; Процент завершения: 78.0%; Средняя LOSS: 3.7531\n",
            "Итерация: 1570; Процент завершения: 78.5%; Средняя LOSS: 3.7456\n",
            "Итерация: 1580; Процент завершения: 79.0%; Средняя LOSS: 3.7688\n",
            "Итерация: 1590; Процент завершения: 79.5%; Средняя LOSS: 3.7631\n",
            "Итерация: 1600; Процент завершения: 80.0%; Средняя LOSS: 3.7464\n",
            "Итерация: 1610; Процент завершения: 80.5%; Средняя LOSS: 3.7355\n",
            "Итерация: 1620; Процент завершения: 81.0%; Средняя LOSS: 3.6993\n",
            "Итерация: 1630; Процент завершения: 81.5%; Средняя LOSS: 3.7429\n",
            "Итерация: 1640; Процент завершения: 82.0%; Средняя LOSS: 3.7633\n",
            "Итерация: 1650; Процент завершения: 82.5%; Средняя LOSS: 3.7295\n",
            "Итерация: 1660; Процент завершения: 83.0%; Средняя LOSS: 3.6993\n",
            "Итерация: 1670; Процент завершения: 83.5%; Средняя LOSS: 3.7195\n",
            "Итерация: 1680; Процент завершения: 84.0%; Средняя LOSS: 3.6812\n",
            "Итерация: 1690; Процент завершения: 84.5%; Средняя LOSS: 3.7441\n",
            "Итерация: 1700; Процент завершения: 85.0%; Средняя LOSS: 3.7023\n",
            "Итерация: 1710; Процент завершения: 85.5%; Средняя LOSS: 3.7179\n",
            "Итерация: 1720; Процент завершения: 86.0%; Средняя LOSS: 3.6991\n",
            "Итерация: 1730; Процент завершения: 86.5%; Средняя LOSS: 3.6951\n",
            "Итерация: 1740; Процент завершения: 87.0%; Средняя LOSS: 3.6864\n",
            "Итерация: 1750; Процент завершения: 87.5%; Средняя LOSS: 3.6767\n",
            "Итерация: 1760; Процент завершения: 88.0%; Средняя LOSS: 3.6920\n",
            "Итерация: 1770; Процент завершения: 88.5%; Средняя LOSS: 3.6898\n",
            "Итерация: 1780; Процент завершения: 89.0%; Средняя LOSS: 3.6892\n",
            "Итерация: 1790; Процент завершения: 89.5%; Средняя LOSS: 3.6603\n",
            "Итерация: 1800; Процент завершения: 90.0%; Средняя LOSS: 3.6782\n",
            "Итерация: 1810; Процент завершения: 90.5%; Средняя LOSS: 3.6182\n",
            "Итерация: 1820; Процент завершения: 91.0%; Средняя LOSS: 3.6573\n",
            "Итерация: 1830; Процент завершения: 91.5%; Средняя LOSS: 3.6625\n",
            "Итерация: 1840; Процент завершения: 92.0%; Средняя LOSS: 3.5998\n",
            "Итерация: 1850; Процент завершения: 92.5%; Средняя LOSS: 3.6019\n",
            "Итерация: 1860; Процент завершения: 93.0%; Средняя LOSS: 3.6378\n",
            "Итерация: 1870; Процент завершения: 93.5%; Средняя LOSS: 3.6600\n",
            "Итерация: 1880; Процент завершения: 94.0%; Средняя LOSS: 3.6620\n",
            "Итерация: 1890; Процент завершения: 94.5%; Средняя LOSS: 3.6056\n",
            "Итерация: 1900; Процент завершения: 95.0%; Средняя LOSS: 3.6416\n",
            "Итерация: 1910; Процент завершения: 95.5%; Средняя LOSS: 3.6377\n",
            "Итерация: 1920; Процент завершения: 96.0%; Средняя LOSS: 3.6313\n",
            "Итерация: 1930; Процент завершения: 96.5%; Средняя LOSS: 3.6143\n",
            "Итерация: 1940; Процент завершения: 97.0%; Средняя LOSS: 3.5743\n",
            "Итерация: 1950; Процент завершения: 97.5%; Средняя LOSS: 3.5754\n",
            "Итерация: 1960; Процент завершения: 98.0%; Средняя LOSS: 3.5788\n",
            "Итерация: 1970; Процент завершения: 98.5%; Средняя LOSS: 3.5869\n",
            "Итерация: 1980; Процент завершения: 99.0%; Средняя LOSS: 3.5568\n",
            "Итерация: 1990; Процент завершения: 99.5%; Средняя LOSS: 3.5785\n",
            "Итерация: 2000; Процент завершения: 100.0%; Средняя LOSS: 3.5977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R015eqL2etI"
      },
      "source": [
        "# визуализируем результат LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "sCmyJZQX2etJ",
        "outputId": "0fd639de-71e2-4385-f004-21f97d8ad6b0"
      },
      "source": [
        "plt.plot(LSTM)\r\n",
        "plt.show()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQMX8Pbw2etJ"
      },
      "source": [
        "## Рассчитаем Bleu score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ny9VXzVy2etJ",
        "outputId": "fc5e167c-17f2-4c04-f422-1d004ba71c38"
      },
      "source": [
        "encoder.eval()\r\n",
        "decoder.eval()\r\n",
        "\r\n",
        "searcher = GreedySearchDecoder(encoder, decoder)\r\n",
        "gram1_bleu_score = []\r\n",
        "gram2_bleu_score = []\r\n",
        "for i in range(0,len(testpairs),1):\r\n",
        "  \r\n",
        "  input_sentence = testpairs[i][0]\r\n",
        "  \r\n",
        "  reference = testpairs[i][1:]\r\n",
        "  templist = []\r\n",
        "  for k in range(len(reference)):\r\n",
        "    if(reference[k]!=''):\r\n",
        "      temp = reference[k].split(' ')\r\n",
        "      templist.append(temp)\r\n",
        "  \r\n",
        "  \r\n",
        "  input_sentence = normalizeString(input_sentence)\r\n",
        "  output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\r\n",
        "  output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\r\n",
        "  chencherry = SmoothingFunction()\r\n",
        "  score1 = sentence_bleu(templist,output_words,weights=(1, 0, 0, 0) ,smoothing_function=chencherry.method1)\r\n",
        "  score2 = sentence_bleu(templist,output_words,weights=(0.5, 0.5, 0, 0),smoothing_function=chencherry.method1) \r\n",
        "  gram1_bleu_score.append(score1)\r\n",
        "  gram2_bleu_score.append(score2)\r\n",
        "  if i%1000 == 0:\r\n",
        "    print(i,sum(gram1_bleu_score)/len(gram1_bleu_score),sum(gram2_bleu_score)/len(gram2_bleu_score))\r\n",
        "print(\"Общая оценка Bleu Score для 1 грамм тестовых пар: \", sum(gram1_bleu_score)/len(gram1_bleu_score) )  \r\n",
        "print(\"Общая оценка Bleu Score для 2 грамм тестовых пар: \", sum(gram2_bleu_score)/len(gram2_bleu_score) )  "
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.141080287481769 0.04887164517296948\n",
            "1000 0.16399356405246795 0.07079737591671265\n",
            "2000 0.16770528621528116 0.07784147174804967\n",
            "3000 0.16817446027599053 0.07660481448072631\n",
            "4000 0.17027956131141078 0.07712708061495438\n",
            "5000 0.1702918312411382 0.07767606266830258\n",
            "6000 0.16767045999088515 0.07486532998047822\n",
            "7000 0.1674648001796698 0.07468837960974696\n",
            "8000 0.16783366586567208 0.07552432411860321\n",
            "Общая оценка Bleu Score для 1 грамм тестовых пар:  0.1670786261643222\n",
            "Общая оценка Bleu Score для 2 грамм тестовых пар:  0.07497288187361803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElFQrFO12etK"
      },
      "source": [
        "# Чат на LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojGLu3oY2etK",
        "outputId": "6421e8b8-1156-4774-f526-bedb6fcf3942"
      },
      "source": [
        "evaluateInput(encoder, decoder, searcher, voc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> hi\n",
            "Black: hi . . . . !\n",
            "> what are you doing?\n",
            "Black: i m looking for a phone . . .\n",
            "> okey\n",
            "Error: обнаружено неизвестное слово.\n",
            "> ok\n",
            "Black: you re not gonna get away with me .\n",
            "> q\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}